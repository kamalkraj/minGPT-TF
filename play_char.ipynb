{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "play_char.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamalkraj/minGPT-TF/blob/master/play_char.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPKcB8oczRAq"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kamalkraj/minGPT-TF/blob/master/play_char.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2vGq5k6sEPB",
        "outputId": "b9f484c3-cb2b-4b69-d54f-464fbd66d525"
      },
      "source": [
        "!git clone https://github.com/kamalkraj/minGPT-TF.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'minGPT-TF' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLaIP3ThsV4D",
        "outputId": "d14c0eda-80b2-4a01-a326-f167b5eb06c0"
      },
      "source": [
        "! pip install fastprogress==0.2.3"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastprogress==0.2.3 in /usr/local/lib/python3.7/dist-packages (0.2.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgRpfV6ms652"
      },
      "source": [
        "import os\n",
        "os.chdir('minGPT-TF')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ectbkGZCtZY7",
        "outputId": "ffa08711-1ef8-4392-d015-d9b1d648fb79"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-01 14:42:48--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt.1’\n",
            "\n",
            "\rinput.txt.1           0%[                    ]       0  --.-KB/s               \rinput.txt.1         100%[===================>]   1.06M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-09-01 14:42:48 (45.9 MB/s) - ‘input.txt.1’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nR1nK54so_r"
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from mingpt.model import GPT, GPTConfig"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vS1zBtijsyi7"
      },
      "source": [
        "class CharDataset:\n",
        "\n",
        "    def __init__(self, data, block_size):\n",
        "        chars = sorted(list(set(data)))\n",
        "        data_size, vocab_size = len(data), len(chars)\n",
        "        print('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
        "        \n",
        "        self.stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "        self.itos = { i:ch for i,ch in enumerate(chars) }\n",
        "        self.block_size = block_size\n",
        "        self.vocab_size = vocab_size\n",
        "        self.data = data\n",
        "    \n",
        "    def __len__(self):\n",
        "        return math.ceil(len(self.data) / (self.block_size + 1))\n",
        "\n",
        "    def __iter__(self):\n",
        "        # we're actually going to \"cheat\" and pick a spot in the dataset at random\n",
        "        for _ in range(self.__len__()):\n",
        "            i = np.random.randint(0, len(self.data) - (self.block_size + 1))\n",
        "            chunk = self.data[i:i+self.block_size+1]\n",
        "            dix = [self.stoi[s] for s in chunk]\n",
        "            x = tf.convert_to_tensor(dix[:-1], dtype=tf.int32)\n",
        "            y = tf.convert_to_tensor(dix[1:], dtype=tf.int32)\n",
        "            yield x, y\n",
        "    \n",
        "    __call__ = __iter__"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pY0MWXIbs0o1"
      },
      "source": [
        "block_size = 128 "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmESKrLxtTgk",
        "outputId": "79d3c344-2c08-47e2-83d8-ec651da2fd09"
      },
      "source": [
        "text = open('input.txt', 'r').read()\n",
        "train_dataset_gen = CharDataset(text, block_size) "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data has 1115394 characters, 65 unique.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j28w_BkjtqXN"
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_generator(train_dataset_gen,(tf.int32,tf.int32))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLKzeZ1PttjO"
      },
      "source": [
        "from mingpt.model import GPT, GPTConfig\n",
        "mconf = GPTConfig(train_dataset_gen.vocab_size, train_dataset_gen.block_size,\n",
        "                  n_layer=8, n_head=8, n_embd=512)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjwA59Jpt5hH"
      },
      "source": [
        "from mingpt.trainer import Trainer, TrainerConfig\n",
        "\n",
        "# initialize a trainer instance and kick off training\n",
        "tconf = TrainerConfig(max_epochs=10, batch_size=64, learning_rate=6e-4,\n",
        "                      lr_decay=True, warmup_tokens=512*20, final_tokens=200*len(train_dataset_gen)*block_size,\n",
        "                      num_workers=4)\n",
        "trainer = Trainer(GPT, mconf, train_dataset, len(train_dataset_gen), None, None, tconf)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "73gbBIN8usA4",
        "outputId": "bcf87229-20d4-4072-82b4-9696cba771e4"
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: train loss 346.91553. lr 5.999636e-04\n",
            "epoch 2: train loss 292.35272. lr 5.998533e-04\n",
            "epoch 3: train loss 257.20963. lr 5.996690e-04\n",
            "epoch 4: train loss 231.03250. lr 5.994107e-04\n",
            "epoch 5: train loss 213.96826. lr 5.990785e-04\n",
            "epoch 6: train loss 201.60358. lr 5.986725e-04\n",
            "epoch 7: train loss 192.35039. lr 5.981929e-04\n",
            "epoch 8: train loss 185.77501. lr 5.976396e-04\n",
            "epoch 9: train loss 181.50128. lr 5.970130e-04\n",
            "epoch 10: train loss 176.67290. lr 5.963130e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y68wlKY2uyg2",
        "outputId": "a20f2339-574c-49c5-c7df-a4609924e7b4"
      },
      "source": [
        "# alright, let's sample some character-level shakespear\n",
        "from mingpt.utils import sample\n",
        "\n",
        "context = \"O God, O God!\"\n",
        "x = tf.convert_to_tensor([train_dataset_gen.stoi[s] for s in context], dtype=tf.int32)[None,...]\n",
        "y = sample(trainer.model, x, 2000, temperature=0.9, sample=True, top_k=5)[0]\n",
        "completion = ''.join([train_dataset_gen.itos[int(i)] for i in y])\n",
        "print(completion)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O God, O God! save a strang anger to me, but not\n",
            "A supper to be him a stand an attimation, he will\n",
            "And the hanged to have may a pleased that would\n",
            "A the high with thy cursed to make the cries here,\n",
            "And what I have, that we may may be hum\n",
            "That the placed of the mouth of her hated hate breath\n",
            "A told me think the prince of him for him from thee,\n",
            "The prize his foolish of his play's liege,\n",
            "Wher we home homast to be much all my son.\n",
            "\n",
            "KING LEWIS XI:\n",
            "I'll not be succustor's to the maid had a poor\n",
            "A solenger of truth of my servant, that I do news the sea\n",
            "The horsely have seem of a mean to bless a cut an\n",
            "The seat of the present and to this sake the prison,\n",
            "That will be a streams of make than he seals\n",
            "That I will dear a man, a then to her best.\n",
            "\n",
            "KING RICHARD IIII:\n",
            "Is thou answer thee o' the means of the mind\n",
            "As the power his supose on a fool a must\n",
            "To be him his consencent it on me,\n",
            "Which are strong but answer all him, he stay is:\n",
            "The wear one on the will to-morrow any then they say\n",
            "The said was to the cause that, but we may\n",
            "As he had all their state of mine,\n",
            "And shall have their companiences but with her:\n",
            "And his condemnity was the same that with super\n",
            "And to the season him to them one.\n",
            "\n",
            "Clown:\n",
            "Come, him his come and to be this hand to the place.\n",
            "\n",
            "GREEN:\n",
            "The coldier of a please that supposess'd in to\n",
            "To heaven the hanges a supolity of sollow together,\n",
            "The wear is the most of the streangth with me.\n",
            "\n",
            "KING RICHARD III:\n",
            "She shall have to make he have his land and trust,\n",
            "That whose was to be so farewell brother to the way\n",
            "And to set him the cause heart to be a melth.\n",
            "\n",
            "KING EDWARD IV:\n",
            "Ay, signious and the will of a pair of him to be me\n",
            "To himself to him; and all the consul\n",
            "Off those case is as true of his life,\n",
            "I am that were a lessen have breathe him:\n",
            "The prison may him he to hear them a parliames\n",
            "Toward his comme and them have the sun\n",
            "This would be the strong and as all thy frese\n",
            "To home thy sear an heard the wisdom.\n",
            "\n",
            "GLOUCESTER:\n",
            "What she hath he hast to him? The corner-she brow it?\n",
            "Why, all \n"
          ]
        }
      ]
    }
  ]
}